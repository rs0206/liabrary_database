{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb30b6a9-fd90-4312-a8f8-ed0a5dcfe2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /opt/anaconda3/lib/python3.12/site-packages (37.0.0)\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/lib/python3.12/site-packages (from faker) (2023.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: faker in /opt/anaconda3/lib/python3.12/site-packages (37.0.0)\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/lib/python3.12/site-packages (from faker) (2023.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Data generation complete! Files saved as CSV.\n"
     ]
    }
   ],
   "source": [
    "!pip install faker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "# Number of samples\n",
    "n = 1000\n",
    "\n",
    "# --------------------\n",
    "# Generate Books Table\n",
    "# --------------------\n",
    "def create_books_table(n):\n",
    "    genres = ['Fiction', 'Non-fiction', 'Science', 'History', 'Biography']\n",
    "    languages = ['English', 'Spanish', 'French', 'German', 'Japanese']\n",
    "    publishers = ['Penguin', 'HarperCollins', 'Macmillan', 'Random House', 'Simon & Schuster']\n",
    "    conditions = ['New', 'Good', 'Worn', 'Damaged']  # New column values\n",
    "\n",
    "    # Columns\n",
    "    isbns = [f\"978-{np.random.randint(1000000000, 9999999999)}\" for _ in range(n)]  # Unique ISBNs\n",
    "    titles = [faker.catch_phrase() for _ in range(n)]  # Realistic book titles\n",
    "    authors = [faker.name() for _ in range(n)]  # Realistic author names\n",
    "    genres_data = np.random.choice(genres, size=n)\n",
    "    languages_data = np.random.choice(languages, size=n)\n",
    "    publication_years = np.random.randint(1900, 2023, n)  # Publication years within a valid range\n",
    "    total_copies = np.random.randint(5, 50, n)  # Total inventory of books\n",
    "    available_copies = np.where(\n",
    "        np.random.rand(n) < 0.85,\n",
    "        total_copies - np.random.randint(0, 5, n),  # Available copies (missing for 15%)\n",
    "        np.nan\n",
    "    )\n",
    "    publishers_data = np.random.choice(publishers, size=n)\n",
    "    book_conditions = np.random.choice(conditions, size=n)  # Assign conditions\n",
    "\n",
    "    # Create DataFrame\n",
    "    books_df = pd.DataFrame({\n",
    "        'ISBN': isbns,\n",
    "        'Title': titles,\n",
    "        'Author': authors,\n",
    "        'Genre': genres_data,\n",
    "        'Language': languages_data,\n",
    "        'Publication_Year': publication_years,\n",
    "        'Total_Copies': total_copies,\n",
    "        'Available_Copies': available_copies,\n",
    "        'Publisher': publishers_data,\n",
    "        'Book_Condition': book_conditions  # New column\n",
    "    })\n",
    "\n",
    "    return books_df\n",
    "\n",
    "# --------------------\n",
    "# Generate Members Table\n",
    "# --------------------\n",
    "def create_members_table(n):\n",
    "    member_ids = [f\"M-{i + 1:05d}\" for i in range(n)]\n",
    "    names = [f\"Member {i + 1}\" for i in range(n)]\n",
    "    names = [faker.name() for _ in range(n)]  # Realistic member names\n",
    "    member_types = ['Regular', 'Premium']\n",
    "    member_type_data = np.random.choice(member_types, size=n, p=[0.7, 0.3])  # More Regular members\n",
    "    join_dates = [(datetime.now() - timedelta(days=np.random.randint(1000, 5000))).strftime('%Y-%m-%d') for _ in\n",
    "                  range(n)]\n",
    "    fines_outstanding = np.where(\n",
    "        np.random.rand(n) < 0.8,\n",
    "        np.random.uniform(0, 100, size=n).round(2),  # 80% have fines\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    # Create DataFrame\n",
    "    members_df = pd.DataFrame({\n",
    "        'Member_ID': member_ids,\n",
    "        'Name': names,\n",
    "        'Member_Type': member_type_data,\n",
    "        'Join_Date': join_dates,\n",
    "        'Fine_Outstanding': fines_outstanding,\n",
    "    })\n",
    "\n",
    "    return members_df\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Generate Staff Table\n",
    "# --------------------\n",
    "def create_staff_table(n):\n",
    "    staff_ids = [f\"S-{i + 1:04d}\" for i in range(n)]\n",
    "    names = [f\"Staff {i + 1}\" for i in range(n)]\n",
    "    names = [faker.name() for _ in range(n)]  # Realistic staff names\n",
    "    roles = ['Librarian', 'Assistant']\n",
    "    role_data = np.random.choice(roles, size=n, p=[0.5, 0.5])  # Equal split\n",
    "    hire_dates = [(datetime.now() - timedelta(days=np.random.randint(1000, 5000))).strftime('%Y-%m-%d') for _ in\n",
    "                  range(n)]\n",
    "    weekly_hours = np.random.randint(20, 40, n)\n",
    "\n",
    "    # Create DataFrame\n",
    "    staff_df = pd.DataFrame({\n",
    "        'Staff_ID': staff_ids,\n",
    "        'Name': names,\n",
    "        'Role': role_data,\n",
    "        'Hire_Date': hire_dates,\n",
    "        'Weekly_Hours': weekly_hours,\n",
    "    })\n",
    "\n",
    "    return staff_df\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Generate Borrow Records Table\n",
    "# ------------------------\n",
    "def create_borrow_records(n, members_df, books_df):\n",
    "    transaction_ids = [f\"T-{i + 1:05d}\" for i in range(n)]\n",
    "    member_ids = np.random.choice(members_df['Member_ID'], size=n)\n",
    "    isbns = np.random.choice(books_df['ISBN'], size=n)\n",
    "    borrow_dates = [(datetime.now() - timedelta(days=np.random.randint(5, 365))).strftime('%Y-%m-%d') for _ in range(n)]\n",
    "    due_dates = [(datetime.strptime(bd, '%Y-%m-%d') + timedelta(days=30)).strftime('%Y-%m-%d') for bd in borrow_dates]\n",
    "    return_dates = np.where(\n",
    "        np.random.rand(n) < 0.8,\n",
    "        [(datetime.strptime(bd, '%Y-%m-%d') + timedelta(days=np.random.randint(5, 60))).strftime('%Y-%m-%d') for bd in\n",
    "         borrow_dates],\n",
    "        None\n",
    "    )\n",
    "    fines = np.where(return_dates == None, np.random.uniform(0, 50, size=n).round(2), 0)\n",
    "\n",
    "    # Create DataFrame explicitly correct without redundant column\n",
    "    borrow_df = pd.DataFrame({\n",
    "        'Transaction_ID': transaction_ids,\n",
    "        'Member_ID': member_ids,\n",
    "        'ISBN': isbns,\n",
    "        'Borrow_Date': borrow_dates,\n",
    "        'Due_Date': due_dates,\n",
    "        'Return_Date': return_dates,\n",
    "        'Fine_Amount': fines,\n",
    "    })\n",
    "\n",
    "    return borrow_df\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Generate and Save Data\n",
    "# --------------------\n",
    "# Generate data\n",
    "books_df = create_books_table(1000)\n",
    "members_df = create_members_table(300)\n",
    "staff_df = create_staff_table(50)\n",
    "borrow_df = create_borrow_records(2000, members_df, books_df)\n",
    "\n",
    "# Output data to CSVs\n",
    "books_df.to_csv('Books.csv', index=False)\n",
    "members_df.to_csv('Members.csv', index=False)\n",
    "staff_df.to_csv('Staff.csv', index=False)\n",
    "borrow_df.to_csv('Borrow_Records.csv', index=False)\n",
    "\n",
    "print(\"Data generation complete! Files saved as CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388aea9-2a24-4bd7-8c74-7b28b025ac98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10543b3-88f4-4e81-a969-ac12f2fbb546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c13e8-cdc5-44f2-8cd6-77afe1bd6ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf4d21-3b9a-495f-bc4f-4d208314a656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609f596-503d-4fb5-bb97-c3468bf150db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
